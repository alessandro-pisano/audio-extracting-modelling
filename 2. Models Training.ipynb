{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f91ff1",
   "metadata": {},
   "source": [
    "# Models\n",
    "In this notebook, all the training process for models used for the work can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa46d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary packages\n",
    "from collections import Counter\n",
    "from official.nlp import optimization  \n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Annotted files\n",
    "df = pd.read_csv(\"Annotated_Files.csv\")\n",
    "\n",
    "list_emotions = [\"Angry\",\n",
    "                \"Bored\",\n",
    "                \"Happy\",\n",
    "                \"Sad\",\n",
    "                \"Surprised\",\n",
    "                \"Neutral\"]\n",
    "\n",
    "# Removing No Audio files\n",
    "to_rem = [\"Can't play the audio\",\n",
    "          'No  audio', \n",
    "          'No audio',\n",
    "          'No one is talking', \n",
    "          'No other', \n",
    "          'No voice', \n",
    "          'Noise', \n",
    "          'None',\n",
    "          'Other']\n",
    "\n",
    "# Encoding Happy sentiments\n",
    "happy_lab = [\"Excited\", \n",
    "             \"Laughing\", \n",
    "             \"Grateful\", \n",
    "             \"Glad\",\n",
    "             \"Good\", \n",
    "             \"Hyped\", \n",
    "             \"Satisfied\"]\n",
    "\n",
    "df[\"label\"] = df[\"Answer\"].str.strip().str.capitalize()\n",
    "df = df[~df[\"label\"].isin(to_rem)].copy()\n",
    "df.loc[df[\"label\"].isin(happy_lab), \"label\"] = \"Happy\"\n",
    "df = df.loc[df[\"label\"].isin(list_emotions)].copy()\n",
    "df[\"augment\"] = \"NA\"\n",
    "df[\"file_path\"] = \"All_Audio/\" + df[\"file_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4775f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import train_test_split\n",
    "\n",
    "# Train test split\n",
    "train, val_ = train_test_split(df, test_size=0.3, random_state=42)\n",
    "dev, test = train_test_split(val_, test_size=0.5, random_state=42)\n",
    "\n",
    "print('Training set size', len(train))\n",
    "print('Validation set size', len(dev))\n",
    "print('Test set size', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning Augumentation to Audio files\n",
    "df2 = train.groupby('label').count().sort_values(by = 'label', ascending = False).reset_index()\n",
    "min_value = df2[\"file_name\"].min()\n",
    "augment_type = [\"low_noise\", \n",
    "                \"high_noise\", \n",
    "                \"slower\", \n",
    "                \"faster\",\n",
    "                \"pitch\",\n",
    "                \"slow_low_noise\",\n",
    "                \"fast_low_noise\",\n",
    "                \"slow_high_noise\",\n",
    "                \"fast_high_noise\"]\n",
    "\n",
    "df_filter = train[train[\"label\"]!=\"Neutral\"].copy()\n",
    "numb_neut = train[train[\"label\"] == \"Neutral\"].count()[0]\n",
    "\n",
    "list_em_no_neut = [\"Angry\",\n",
    "                \"Bored\",\n",
    "                \"Happy\",\n",
    "                \"Sad\",\n",
    "                \"Surprised\"]\n",
    "\n",
    "for aug in augment_type:\n",
    "    df_aug = df_filter.copy()\n",
    "    for emot in list_em_no_neut:\n",
    "        if (train[train[\"label\"]==emot].count()[0] > numb_neut) | (emot ==\"Neutral\"):\n",
    "            print(\"hey\",train[train[\"label\"]==emot].count()[0] )\n",
    "            aug_file = df_aug[df_aug[\"label\"]==emot][\"file_name\"].sample(min_value)\n",
    "            df_aug.loc[df_aug[\"file_name\"].isin(aug_file), \"augment\"] = \"NA\"\n",
    "        else:\n",
    "            aug_file = df_aug[df_aug[\"label\"]==emot][\"file_name\"].sample(min_value)\n",
    "            df_aug.loc[df_aug[\"file_name\"].isin(aug_file), \"augment\"] = aug\n",
    "    df_aug = df_aug[df_aug[\"augment\"]!=\"NA\"].copy()\n",
    "    train = pd.concat([train, df_aug]).sort_values(\"folder\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train = np.array(label_encoder.fit_transform(train['label'].values.tolist()))\n",
    "y_val = np.array(label_encoder.fit_transform(dev['label'].values.tolist()))\n",
    "y_test = np.array(label_encoder.fit_transform(test['label'].values.tolist()))\n",
    "\n",
    "X_train_path = train[\"file_path\"].to_numpy()\n",
    "X_val_path = dev[\"file_path\"].to_numpy()\n",
    "X_test_path = test[\"file_path\"].to_numpy()\n",
    "\n",
    "aug_train = train[\"augment\"].to_numpy()\n",
    "aug_val = dev[\"augment\"].to_numpy()\n",
    "aug_test = test[\"augment\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b06de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Audio_Generator\n",
    "\n",
    "batch_size = 32\n",
    "# Saving Data generator\n",
    "train_batch_generator = Audio_Generator(X_train_path, y_train, aug_train, batch_size)\n",
    "val_batch_generator = Audio_Generator(X_val_path, y_val, aug_val, batch_size)\n",
    "test_batch_generator = Audio_Generator(X_test_path, y_test, aug_test, batch_size)\n",
    "\n",
    "input_shape = (40, 844, 1)\n",
    "num_labels = len(list_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bfc014",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "The ResNet is the model which performed better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "from models import create_res_net\n",
    "\n",
    "# Training\n",
    "batch_size = 16\n",
    "opt = \"sgd\"\n",
    "name = \"res_net\"\n",
    "input_shape = (160, 211, 1)\n",
    "num_labels = len(list_emotions)\n",
    "model_audio = create_res_net(opt, input_shape, num_labels)\n",
    "\n",
    "# With this callback we save the weights of the best epoch based on val_loss\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights/'+opt+str(batch_size)+'_'+name+'weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_f1_l',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model_audio.fit(train_batch_generator, \n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=2,\n",
    "                  validation_data=val_batch_generator,\n",
    "                  callbacks=[model_checkpoint_callback],\n",
    "                  max_queue_size=20,\n",
    "                  workers=45,\n",
    "                  use_multiprocessing=True)\n",
    "\n",
    "loss, accuracy, recall, precision, f1_l  = model_audio.evaluate(test_batch_generator,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=False,\n",
    "                                workers=30,\n",
    "                                use_multiprocessing=True)\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.to_csv(f'log/{opt+str(batch_size)}_batch_{str(epochs)}_{name}.csv', index=False)\n",
    "\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"\\nTesting Recall:  {:.4f}\".format(recall))\n",
    "print(\"\\nTesting Precision:  {:.4f}\".format(precision))\n",
    "print(\"\\nTesting F1:  {:.4f}\".format(f1_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f5d55",
   "metadata": {},
   "source": [
    "## CONV LSTM\n",
    "To train the model, we split the conversations in dialogues of length 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a100c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into shorter dialogues\n",
    "file_parse_df = df.groupby(\"folder\", sort=False)[\"file_name\"].count()//10*10\n",
    "df_in = pd.DataFrame()\n",
    "for folder, value in file_parse_df.iteritems():\n",
    "    df_in = pd.concat((df_in,df[df[\"folder\"]==folder][:value]))\n",
    "\n",
    "df_in['group_id'] = np.arange(len(df_in))//10\n",
    "groups = [df for _, df in df_in.groupby('group_id')]\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(groups)\n",
    "df_in = pd.concat(groups).reset_index(drop=True)\n",
    "\n",
    "train = df_in[:39910].copy()\n",
    "dev = df_in[39910:48460].copy()\n",
    "test = df_in[48460:].copy()\n",
    "\n",
    "print('Training set size', len(train))\n",
    "print('Validation set size', len(dev))\n",
    "print('Test set size', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1059b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Audio_Generator_CNNLSTM\n",
    "\n",
    "# Generator\n",
    "batch_size = group_sent = 20\n",
    "\n",
    "X_test_path = test[\"file_path\"].to_numpy()[:test.shape[0]//group_sent*group_sent]\n",
    "aug_test = test[\"augment\"].to_numpy()[:test.shape[0]//group_sent*group_sent]\n",
    "y_test = np.array(label_encoder.fit_transform(test['label'].values\\\n",
    "                                              .tolist()))[:X_test_path.shape[0]//group_sent*group_sent]\n",
    "test_batch_generator = c(X_test_path, y_test, aug_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "from models import ConvLSTM_Model\n",
    "\n",
    "# Training\n",
    "batch_size = 16\n",
    "opt = \"sgd\"\n",
    "name = \"cnn_lstm\"\n",
    "\n",
    "model_cnn_lstm = ConvLSTM_Model(10, 40, 844, 1, list_emotions)\n",
    "model_cnn_lstm.compile(optimizer= opt,\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'\n",
    "                       ])\n",
    "\n",
    "# With this callback we save the weights of the best epoch based on val_loss\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights/'+opt+str(batch_size)+'_'+name+'weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_f1_l',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model_cnn_lstm.fit(train_batch_generator, \n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=2,\n",
    "                  validation_data=val_batch_generator,\n",
    "                  callbacks=[model_checkpoint_callback],\n",
    "                  max_queue_size=20,\n",
    "                  workers=45,\n",
    "                  use_multiprocessing=True)\n",
    "\n",
    "loss, accuracy, recall, precision, f1_l  = model_cnn_lstm.evaluate(test_batch_generator,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=False,\n",
    "                                workers=30,\n",
    "                                use_multiprocessing=True)\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.to_csv(f'log/{opt+str(batch_size)}_batch_{str(epochs)}_{name}.csv', index=False)\n",
    "\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"\\nTesting Recall:  {:.4f}\".format(recall))\n",
    "print(\"\\nTesting Precision:  {:.4f}\".format(precision))\n",
    "print(\"\\nTesting F1:  {:.4f}\".format(f1_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8432b371",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbecc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "from models import model_alex\n",
    "\n",
    "# Training\n",
    "input_shape = (160, 211, 1)\n",
    "num_labels = len(list_emotions)\n",
    "batch_size = 16\n",
    "opt = \"sgd\"\n",
    "name = \"alexnet\"\n",
    "\n",
    "model_alex = model_alex(opt, input_shape, num_labels)\n",
    "model_alex.compile(optimizer= opt,\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'\n",
    "                       ])\n",
    "\n",
    "# With this callback we save the weights of the best epoch based on val_loss\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights/'+opt+str(batch_size)+'_'+name+'weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_f1_l',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model_alex.fit(train_batch_generator, \n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=2,\n",
    "                  validation_data=val_batch_generator,\n",
    "                  callbacks=[model_checkpoint_callback],\n",
    "                  max_queue_size=20,\n",
    "                  workers=45,\n",
    "                  use_multiprocessing=True)\n",
    "\n",
    "loss, accuracy, recall, precision, f1_l  = model_alex.evaluate(test_batch_generator,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=False,\n",
    "                                workers=30,\n",
    "                                use_multiprocessing=True)\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.to_csv(f'log/{opt+str(batch_size)}_batch_{str(epochs)}_{name}.csv', index=False)\n",
    "\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"\\nTesting Recall:  {:.4f}\".format(recall))\n",
    "print(\"\\nTesting Precision:  {:.4f}\".format(precision))\n",
    "print(\"\\nTesting F1:  {:.4f}\".format(f1_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9bafd",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "from models import model_vgg\n",
    "\n",
    "# Training\n",
    "input_shape = (160, 211, 1)\n",
    "num_labels = len(list_emotions)\n",
    "batch_size = 16\n",
    "opt = \"sgd\"\n",
    "name = \"vggnet\"\n",
    "\n",
    "model_vgg_ = model_vgg(opt, input_shape, num_labels)\n",
    "model_vgg_.compile(optimizer= opt,\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'\n",
    "                       ])\n",
    "\n",
    "# With this callback we save the weights of the best epoch based on val_loss\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights/'+opt+str(batch_size)+'_'+name+'weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_f1_l',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model_vgg_.fit(train_batch_generator, \n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=2,\n",
    "                  validation_data=val_batch_generator,\n",
    "                  callbacks=[model_checkpoint_callback],\n",
    "                  max_queue_size=20,\n",
    "                  workers=45,\n",
    "                  use_multiprocessing=True)\n",
    "\n",
    "loss, accuracy, recall, precision, f1_l  = model_vgg_.evaluate(test_batch_generator,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=False,\n",
    "                                workers=30,\n",
    "                                use_multiprocessing=True)\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.to_csv(f'log/{opt+str(batch_size)}_batch_{str(epochs)}_{name}.csv', index=False)\n",
    "\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"\\nTesting Recall:  {:.4f}\".format(recall))\n",
    "print(\"\\nTesting Precision:  {:.4f}\".format(precision))\n",
    "print(\"\\nTesting F1:  {:.4f}\".format(f1_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64762569",
   "metadata": {},
   "source": [
    "---\n",
    "# Textual Features Models\n",
    "Models Trained on the Transcripts, not on the audio features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dacf1b",
   "metadata": {},
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading dataset \n",
    "df = pd.read_csv(\"Annotated_Files.csv\")\n",
    "\n",
    "list_emotions = [\"Angry\",\n",
    "                \"Bored\",\n",
    "                \"Happy\",\n",
    "                \"Sad\",\n",
    "                \"Surprised\",\n",
    "                \"Neutral\"]\n",
    "\n",
    "df[\"label\"] = df[\"Answer\"].str.strip().str.capitalize()\n",
    "df = df[~df[\"label\"].isin(to_rem)].copy()\n",
    "df.loc[df[\"label\"].isin(happy_lab), \"label\"] = \"Happy\"\n",
    "df = df.loc[df[\"label\"].isin(list_emotions)].copy()\n",
    "df[\"augment\"] = \"NA\"\n",
    "df[\"file_path\"] = \"All_Audio/\" + df[\"file_name\"]\n",
    "\n",
    "# Splitting\n",
    "train, dev, test = split_data(df, train_dim= 0.70, dev_dim=0.15, test_dim=0.15)\n",
    "print('Training set size', len(train))\n",
    "print('Validation set size', len(dev))\n",
    "print('Test set size', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining all text\n",
    "text_all = [' '.join(clean_text(text)) for text in df[\"Transcript\"]]\n",
    "train_text = [' '.join(clean_text(text)) for text in train[\"Transcript\"]]\n",
    "val_text = [' '.join(clean_text(text)) for text in dev[\"Transcript\"]]\n",
    "test_text = [' '.join(clean_text(text)) for text in test[\"Transcript\"]]\n",
    "\n",
    "# Tokenizing\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_all)\n",
    "sequence_train=tokenizer.texts_to_sequences(train_text)\n",
    "sequence_val=tokenizer.texts_to_sequences(val_text)\n",
    "sequence_test=tokenizer.texts_to_sequences(test_text)\n",
    "index_of_words=tokenizer.word_index\n",
    "vocab_size=len(index_of_words)+1\n",
    "embed_num_dims=300\n",
    "max_seq_len=40\n",
    "\n",
    "# Padding sequences\n",
    "X_train_pad =pad_sequences(sequence_train, maxlen=max_seq_len)\n",
    "X_val_pad =pad_sequences(sequence_val, maxlen=max_seq_len)\n",
    "X_test_pad =pad_sequences(sequence_test, maxlen=max_seq_len)\n",
    "\n",
    "# Encoding Labels\n",
    "y_train = np.array(label_encoder.fit_transform(train['label'].values.tolist()))\n",
    "y_val = np.array(label_encoder.fit_transform(dev['label'].values.tolist()))\n",
    "y_test = np.array(label_encoder.fit_transform(test['label'].values.tolist()))\n",
    "\n",
    "# Embedding Matrix\n",
    "fname='crawl-300d-2M.vec'\n",
    "embedd_matrix=create_embedding_matrix(fname,index_of_words,embed_num_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bbc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "from models import model_text\n",
    "\n",
    "# Training\n",
    "batch_size = 16\n",
    "opt = \"sgd\"\n",
    "name = \"bilstm\"\n",
    "num_labels = len(list_emotions)\n",
    "model_text_ = model_text(opt,vocab_size,embed_num_dims,max_seq_len,embedd_matrix,num_labels)\n",
    "model_text_.compile(optimizer= opt,\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'\n",
    "                       ])\n",
    "\n",
    "# With this callback we save the weights of the best epoch based on val_loss\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights/'+opt+str(batch_size)+'_'+name+'weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_f1_l',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model_text_.fit(X_train_pad,y_train,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(X_val_pad,y_val),\n",
    "               verbose=2,\n",
    "               callbacks=[model_checkpoint_callback],\n",
    "               use_multiprocessing=True)\n",
    "\n",
    "loss, accuracy, recall, precision, f1_l  = model_text_.evaluate(X_test_pad,y_test,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=False)\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.to_csv(f'log/{opt+str(batch_size)}_batch_{str(epochs)}_{name}.csv', index=False)\n",
    "\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"\\nTesting Recall:  {:.4f}\".format(recall))\n",
    "print(\"\\nTesting Precision:  {:.4f}\".format(precision))\n",
    "print(\"\\nTesting F1:  {:.4f}\".format(f1_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c884439",
   "metadata": {},
   "source": [
    "### Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b6484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert model and preprocess\n",
    "bert_model = 'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3'\n",
    "bert_preprocess = 'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3'\n",
    "\n",
    "bert_preprocess_model = hub.KerasLayer(bert_preprocess)\n",
    "bert_model = hub.KerasLayer(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf8cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import TextGenerator\n",
    "\n",
    "# Saving Text\n",
    "X_train_text = train[\"Transcript\"].to_numpy()\n",
    "X_val_text = dev[\"Transcript\"].to_numpy()\n",
    "X_test_text = test[\"Transcript\"].to_numpy()\n",
    "\n",
    "# Bert Generator\n",
    "batch_size = 32\n",
    "train_batch_generator = TextGenerator(X_train_text, y_train, batch_size)\n",
    "val_batch_generator = TextGenerator(X_val_text, y_val, batch_size)\n",
    "test_batch_generator = TextGenerator(X_test_text, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a16d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "from models import model_vgg\n",
    "\n",
    "# Training\n",
    "input_shape = (128, 512, 1)\n",
    "num_labels = len(list_emotions)\n",
    "batch_size = 16\n",
    "opt = \"sgd\"\n",
    "name = \"bert\"\n",
    "model_bert_ = model_bert(opt, bert_preprocess_model, num_labels)\n",
    "model_bert_.compile(optimizer= opt,\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'\n",
    "                       ])\n",
    "\n",
    "# With this callback we save the weights of the best epoch based on val_loss\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights/'+opt+str(batch_size)+'_'+name+'weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_f1_l',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model_bert_.fit(train_batch_generator, \n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=2,\n",
    "                  validation_data=val_batch_generator,\n",
    "                  callbacks=[model_checkpoint_callback],\n",
    "                  max_queue_size=20,\n",
    "                  workers=45,\n",
    "                  use_multiprocessing=True)\n",
    "\n",
    "loss, accuracy, recall, precision, f1_l  = model_bert_.evaluate(test_batch_generator,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=False,\n",
    "                                workers=30,\n",
    "                                use_multiprocessing=True)\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.to_csv(f'log/{opt+str(batch_size)}_batch_{str(epochs)}_{name}.csv', index=False)\n",
    "\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"\\nTesting Recall:  {:.4f}\".format(recall))\n",
    "print(\"\\nTesting Precision:  {:.4f}\".format(precision))\n",
    "print(\"\\nTesting F1:  {:.4f}\".format(f1_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9106bcd2",
   "metadata": {},
   "source": [
    "---\n",
    "# Combined Model - Multimodal\n",
    "Here, the model combining the two features, audio and text. The best weights of the best perforiming model has been used: ResNet and BiLSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the models\n",
    "from models import CombinedGenerator, model_combined\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = np.array(label_encoder.fit_transform(train['label'].values.tolist()))\n",
    "y_val = np.array(label_encoder.fit_transform(dev['label'].values.tolist()))\n",
    "y_test = np.array(label_encoder.fit_transform(test['label'].values.tolist()))\n",
    "\n",
    "X_train_text = train[\"Transcript\"].to_numpy()\n",
    "X_val_text = dev[\"Transcript\"].to_numpy()\n",
    "X_test_text = test[\"Transcript\"].to_numpy()\n",
    "\n",
    "X_train_path = train[\"file_path\"].to_numpy()\n",
    "X_val_path = dev[\"file_path\"].to_numpy()\n",
    "X_test_path = test[\"file_path\"].to_numpy()\n",
    "\n",
    "aug_train = train[\"augment\"].to_numpy()\n",
    "aug_val = dev[\"augment\"].to_numpy()\n",
    "aug_test = test[\"augment\"].to_numpy()\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_combined_generator = CombinedGenerator(X_train_path, y_train, aug_train, X_train_pad, batch_size)\n",
    "val_combined_generator = CombinedGenerator(X_val_path, y_val, aug_val, X_val_pad, batch_size)\n",
    "test_combined_generator = CombinedGenerator(X_test_path, y_test, aug_test, X_test_pad, batch_size)\n",
    "\n",
    "# Loading best weights\n",
    "batch_size = 16\n",
    "opt = \"sgd\"\n",
    "input_shape = (160, 211, 1)\n",
    "num_labels = len(list_emotions)\n",
    "\n",
    "model_audio = create_res_net(\"sgd\", input_shape, num_labels)\n",
    "model_audio.load_weights(\"weights/Best_ResNet_SGD.12-2.34.hdf5\")   \n",
    "\n",
    "model_txt = model_text(\"adam\",vocab_size,embed_num_dims,max_seq_len,embedd_matrix,num_labels)\n",
    "model_txt.load_weights(\"weights/Best_BILSTM_text_embeddings.30-2.72.hdf5\")\n",
    "print(\"done loading\")\n",
    "\n",
    "model = model_combined(model_audio, model_txt, \"sgd\")\n",
    "\n",
    "epochs = 50 \n",
    "name = \"combined_res_bilstm\"\n",
    "opt = \"SGD\"\n",
    "\n",
    "model.compile(optimizer= opt,\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy', \n",
    "                       recall, \n",
    "                       precision, \n",
    "                       f1_l\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10368f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this callback we save the weights of the best epoch based on val_loss\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights/'+opt+str(batch_size)+'_'+name+'weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_f1_l',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "history = model.fit(train_combined_generator, \n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=2,\n",
    "                  validation_data=val_combined_generator,\n",
    "                  callbacks=[model_checkpoint_callback],\n",
    "                  max_queue_size=20,\n",
    "                  workers=45,\n",
    "                  use_multiprocessing=True)\n",
    "\n",
    "\n",
    "loss, accuracy, recall, precision, f1_l  = model.evaluate(test_combined_generator,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=False,\n",
    "                                workers=30,\n",
    "                                use_multiprocessing=True)\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.to_csv(f'log/{opt+str(batch_size)}_batch_{str(epochs)}_{name}.csv', index=False)\n",
    "print(\"\\nTesting Accuracy:  {:.4f}\".format(accuracy))\n",
    "print(\"\\nTesting Recall:  {:.4f}\".format(recall))\n",
    "print(\"\\nTesting Precision:  {:.4f}\".format(precision))\n",
    "print(\"\\nTesting F1:  {:.4f}\".format(f1_l))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
